Model: "efficientnetb0"
+--------------------------------------------------------------------------------------------+
| Layer (type)              | Output Shape          |       Param # | Connected to           |
|---------------------------+-----------------------+---------------+------------------------|
| input_layer (InputLayer)  | (None, 224, 224, 3)   |             0 | -                      |
|---------------------------+-----------------------+---------------+------------------------|
| rescaling (Rescaling)     | (None, 224, 224, 3)   |             0 | input_layer[0][0]      |
|---------------------------+-----------------------+---------------+------------------------|
| normalization             | (None, 224, 224, 3)   |             7 | rescaling[0][0]        |
| (Normalization)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| rescaling_1 (Rescaling)   | (None, 224, 224, 3)   |             0 | normalization[0][0]    |
|---------------------------+-----------------------+---------------+------------------------|
| stem_conv_pad             | (None, 225, 225, 3)   |             0 | rescaling_1[0][0]      |
| (ZeroPadding2D)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| stem_conv (Conv2D)        | (None, 112, 112, 32)  |           864 | stem_conv_pad[0][0]    |
|---------------------------+-----------------------+---------------+------------------------|
| stem_bn                   | (None, 112, 112, 32)  |           128 | stem_conv[0][0]        |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| stem_activation           | (None, 112, 112, 32)  |             0 | stem_bn[0][0]          |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_dwconv            | (None, 112, 112, 32)  |           288 | stem_activation[0][0]  |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_bn                | (None, 112, 112, 32)  |           128 | block1a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_activation        | (None, 112, 112, 32)  |             0 | block1a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_se_squeeze        | (None, 32)            |             0 | block1a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_se_reshape        | (None, 1, 1, 32)      |             0 | block1a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_se_reduce         | (None, 1, 1, 8)       |           264 | block1a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_se_expand         | (None, 1, 1, 32)      |           288 | block1a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_se_excite         | (None, 112, 112, 32)  |             0 | block1a_activation[0]… |
| (Multiply)                |                       |               | block1a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_project_conv      | (None, 112, 112, 16)  |           512 | block1a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block1a_project_bn        | (None, 112, 112, 16)  |            64 | block1a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_expand_conv       | (None, 112, 112, 96)  |         1,536 | block1a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_expand_bn         | (None, 112, 112, 96)  |           384 | block2a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_expand_activation | (None, 112, 112, 96)  |             0 | block2a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_dwconv_pad        | (None, 113, 113, 96)  |             0 | block2a_expand_activa… |
| (ZeroPadding2D)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_dwconv            | (None, 56, 56, 96)    |           864 | block2a_dwconv_pad[0]… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_bn                | (None, 56, 56, 96)    |           384 | block2a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_activation        | (None, 56, 56, 96)    |             0 | block2a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_se_squeeze        | (None, 96)            |             0 | block2a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_se_reshape        | (None, 1, 1, 96)      |             0 | block2a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_se_reduce         | (None, 1, 1, 4)       |           388 | block2a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_se_expand         | (None, 1, 1, 96)      |           480 | block2a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_se_excite         | (None, 56, 56, 96)    |             0 | block2a_activation[0]… |
| (Multiply)                |                       |               | block2a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_project_conv      | (None, 56, 56, 24)    |         2,304 | block2a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2a_project_bn        | (None, 56, 56, 24)    |            96 | block2a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_expand_conv       | (None, 56, 56, 144)   |         3,456 | block2a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_expand_bn         | (None, 56, 56, 144)   |           576 | block2b_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_expand_activation | (None, 56, 56, 144)   |             0 | block2b_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_dwconv            | (None, 56, 56, 144)   |         1,296 | block2b_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_bn                | (None, 56, 56, 144)   |           576 | block2b_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_activation        | (None, 56, 56, 144)   |             0 | block2b_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_se_squeeze        | (None, 144)           |             0 | block2b_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_se_reshape        | (None, 1, 1, 144)     |             0 | block2b_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_se_reduce         | (None, 1, 1, 6)       |           870 | block2b_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_se_expand         | (None, 1, 1, 144)     |         1,008 | block2b_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_se_excite         | (None, 56, 56, 144)   |             0 | block2b_activation[0]… |
| (Multiply)                |                       |               | block2b_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_project_conv      | (None, 56, 56, 24)    |         3,456 | block2b_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_project_bn        | (None, 56, 56, 24)    |            96 | block2b_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_drop (Dropout)    | (None, 56, 56, 24)    |             0 | block2b_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block2b_add (Add)         | (None, 56, 56, 24)    |             0 | block2b_drop[0][0],    |
|                           |                       |               | block2a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_expand_conv       | (None, 56, 56, 144)   |         3,456 | block2b_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_expand_bn         | (None, 56, 56, 144)   |           576 | block3a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_expand_activation | (None, 56, 56, 144)   |             0 | block3a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_dwconv_pad        | (None, 59, 59, 144)   |             0 | block3a_expand_activa… |
| (ZeroPadding2D)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_dwconv            | (None, 28, 28, 144)   |         3,600 | block3a_dwconv_pad[0]… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_bn                | (None, 28, 28, 144)   |           576 | block3a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_activation        | (None, 28, 28, 144)   |             0 | block3a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_se_squeeze        | (None, 144)           |             0 | block3a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_se_reshape        | (None, 1, 1, 144)     |             0 | block3a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_se_reduce         | (None, 1, 1, 6)       |           870 | block3a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_se_expand         | (None, 1, 1, 144)     |         1,008 | block3a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_se_excite         | (None, 28, 28, 144)   |             0 | block3a_activation[0]… |
| (Multiply)                |                       |               | block3a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_project_conv      | (None, 28, 28, 40)    |         5,760 | block3a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3a_project_bn        | (None, 28, 28, 40)    |           160 | block3a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_expand_conv       | (None, 28, 28, 240)   |         9,600 | block3a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_expand_bn         | (None, 28, 28, 240)   |           960 | block3b_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_expand_activation | (None, 28, 28, 240)   |             0 | block3b_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_dwconv            | (None, 28, 28, 240)   |         6,000 | block3b_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_bn                | (None, 28, 28, 240)   |           960 | block3b_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_activation        | (None, 28, 28, 240)   |             0 | block3b_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_se_squeeze        | (None, 240)           |             0 | block3b_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_se_reshape        | (None, 1, 1, 240)     |             0 | block3b_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_se_reduce         | (None, 1, 1, 10)      |         2,410 | block3b_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_se_expand         | (None, 1, 1, 240)     |         2,640 | block3b_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_se_excite         | (None, 28, 28, 240)   |             0 | block3b_activation[0]… |
| (Multiply)                |                       |               | block3b_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_project_conv      | (None, 28, 28, 40)    |         9,600 | block3b_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_project_bn        | (None, 28, 28, 40)    |           160 | block3b_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_drop (Dropout)    | (None, 28, 28, 40)    |             0 | block3b_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block3b_add (Add)         | (None, 28, 28, 40)    |             0 | block3b_drop[0][0],    |
|                           |                       |               | block3a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_expand_conv       | (None, 28, 28, 240)   |         9,600 | block3b_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_expand_bn         | (None, 28, 28, 240)   |           960 | block4a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_expand_activation | (None, 28, 28, 240)   |             0 | block4a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_dwconv_pad        | (None, 29, 29, 240)   |             0 | block4a_expand_activa… |
| (ZeroPadding2D)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_dwconv            | (None, 14, 14, 240)   |         2,160 | block4a_dwconv_pad[0]… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_bn                | (None, 14, 14, 240)   |           960 | block4a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_activation        | (None, 14, 14, 240)   |             0 | block4a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_se_squeeze        | (None, 240)           |             0 | block4a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_se_reshape        | (None, 1, 1, 240)     |             0 | block4a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_se_reduce         | (None, 1, 1, 10)      |         2,410 | block4a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_se_expand         | (None, 1, 1, 240)     |         2,640 | block4a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_se_excite         | (None, 14, 14, 240)   |             0 | block4a_activation[0]… |
| (Multiply)                |                       |               | block4a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_project_conv      | (None, 14, 14, 80)    |        19,200 | block4a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4a_project_bn        | (None, 14, 14, 80)    |           320 | block4a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_expand_conv       | (None, 14, 14, 480)   |        38,400 | block4a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_expand_bn         | (None, 14, 14, 480)   |         1,920 | block4b_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_expand_activation | (None, 14, 14, 480)   |             0 | block4b_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_dwconv            | (None, 14, 14, 480)   |         4,320 | block4b_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_bn                | (None, 14, 14, 480)   |         1,920 | block4b_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_activation        | (None, 14, 14, 480)   |             0 | block4b_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_se_squeeze        | (None, 480)           |             0 | block4b_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_se_reshape        | (None, 1, 1, 480)     |             0 | block4b_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_se_reduce         | (None, 1, 1, 20)      |         9,620 | block4b_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_se_expand         | (None, 1, 1, 480)     |        10,080 | block4b_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_se_excite         | (None, 14, 14, 480)   |             0 | block4b_activation[0]… |
| (Multiply)                |                       |               | block4b_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_project_conv      | (None, 14, 14, 80)    |        38,400 | block4b_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_project_bn        | (None, 14, 14, 80)    |           320 | block4b_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_drop (Dropout)    | (None, 14, 14, 80)    |             0 | block4b_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block4b_add (Add)         | (None, 14, 14, 80)    |             0 | block4b_drop[0][0],    |
|                           |                       |               | block4a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_expand_conv       | (None, 14, 14, 480)   |        38,400 | block4b_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_expand_bn         | (None, 14, 14, 480)   |         1,920 | block4c_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_expand_activation | (None, 14, 14, 480)   |             0 | block4c_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_dwconv            | (None, 14, 14, 480)   |         4,320 | block4c_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_bn                | (None, 14, 14, 480)   |         1,920 | block4c_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_activation        | (None, 14, 14, 480)   |             0 | block4c_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_se_squeeze        | (None, 480)           |             0 | block4c_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_se_reshape        | (None, 1, 1, 480)     |             0 | block4c_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_se_reduce         | (None, 1, 1, 20)      |         9,620 | block4c_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_se_expand         | (None, 1, 1, 480)     |        10,080 | block4c_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_se_excite         | (None, 14, 14, 480)   |             0 | block4c_activation[0]… |
| (Multiply)                |                       |               | block4c_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_project_conv      | (None, 14, 14, 80)    |        38,400 | block4c_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_project_bn        | (None, 14, 14, 80)    |           320 | block4c_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_drop (Dropout)    | (None, 14, 14, 80)    |             0 | block4c_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block4c_add (Add)         | (None, 14, 14, 80)    |             0 | block4c_drop[0][0],    |
|                           |                       |               | block4b_add[0][0]      |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_expand_conv       | (None, 14, 14, 480)   |        38,400 | block4c_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_expand_bn         | (None, 14, 14, 480)   |         1,920 | block5a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_expand_activation | (None, 14, 14, 480)   |             0 | block5a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_dwconv            | (None, 14, 14, 480)   |        12,000 | block5a_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_bn                | (None, 14, 14, 480)   |         1,920 | block5a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_activation        | (None, 14, 14, 480)   |             0 | block5a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_se_squeeze        | (None, 480)           |             0 | block5a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_se_reshape        | (None, 1, 1, 480)     |             0 | block5a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_se_reduce         | (None, 1, 1, 20)      |         9,620 | block5a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_se_expand         | (None, 1, 1, 480)     |        10,080 | block5a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_se_excite         | (None, 14, 14, 480)   |             0 | block5a_activation[0]… |
| (Multiply)                |                       |               | block5a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_project_conv      | (None, 14, 14, 112)   |        53,760 | block5a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5a_project_bn        | (None, 14, 14, 112)   |           448 | block5a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_expand_conv       | (None, 14, 14, 672)   |        75,264 | block5a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_expand_bn         | (None, 14, 14, 672)   |         2,688 | block5b_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_expand_activation | (None, 14, 14, 672)   |             0 | block5b_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_dwconv            | (None, 14, 14, 672)   |        16,800 | block5b_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_bn                | (None, 14, 14, 672)   |         2,688 | block5b_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_activation        | (None, 14, 14, 672)   |             0 | block5b_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_se_squeeze        | (None, 672)           |             0 | block5b_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_se_reshape        | (None, 1, 1, 672)     |             0 | block5b_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_se_reduce         | (None, 1, 1, 28)      |        18,844 | block5b_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_se_expand         | (None, 1, 1, 672)     |        19,488 | block5b_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_se_excite         | (None, 14, 14, 672)   |             0 | block5b_activation[0]… |
| (Multiply)                |                       |               | block5b_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_project_conv      | (None, 14, 14, 112)   |        75,264 | block5b_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_project_bn        | (None, 14, 14, 112)   |           448 | block5b_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_drop (Dropout)    | (None, 14, 14, 112)   |             0 | block5b_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block5b_add (Add)         | (None, 14, 14, 112)   |             0 | block5b_drop[0][0],    |
|                           |                       |               | block5a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_expand_conv       | (None, 14, 14, 672)   |        75,264 | block5b_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_expand_bn         | (None, 14, 14, 672)   |         2,688 | block5c_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_expand_activation | (None, 14, 14, 672)   |             0 | block5c_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_dwconv            | (None, 14, 14, 672)   |        16,800 | block5c_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_bn                | (None, 14, 14, 672)   |         2,688 | block5c_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_activation        | (None, 14, 14, 672)   |             0 | block5c_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_se_squeeze        | (None, 672)           |             0 | block5c_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_se_reshape        | (None, 1, 1, 672)     |             0 | block5c_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_se_reduce         | (None, 1, 1, 28)      |        18,844 | block5c_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_se_expand         | (None, 1, 1, 672)     |        19,488 | block5c_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_se_excite         | (None, 14, 14, 672)   |             0 | block5c_activation[0]… |
| (Multiply)                |                       |               | block5c_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_project_conv      | (None, 14, 14, 112)   |        75,264 | block5c_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_project_bn        | (None, 14, 14, 112)   |           448 | block5c_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_drop (Dropout)    | (None, 14, 14, 112)   |             0 | block5c_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block5c_add (Add)         | (None, 14, 14, 112)   |             0 | block5c_drop[0][0],    |
|                           |                       |               | block5b_add[0][0]      |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_expand_conv       | (None, 14, 14, 672)   |        75,264 | block5c_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_expand_bn         | (None, 14, 14, 672)   |         2,688 | block6a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_expand_activation | (None, 14, 14, 672)   |             0 | block6a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_dwconv_pad        | (None, 17, 17, 672)   |             0 | block6a_expand_activa… |
| (ZeroPadding2D)           |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_dwconv            | (None, 7, 7, 672)     |        16,800 | block6a_dwconv_pad[0]… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_bn                | (None, 7, 7, 672)     |         2,688 | block6a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_activation        | (None, 7, 7, 672)     |             0 | block6a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_se_squeeze        | (None, 672)           |             0 | block6a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_se_reshape        | (None, 1, 1, 672)     |             0 | block6a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_se_reduce         | (None, 1, 1, 28)      |        18,844 | block6a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_se_expand         | (None, 1, 1, 672)     |        19,488 | block6a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_se_excite         | (None, 7, 7, 672)     |             0 | block6a_activation[0]… |
| (Multiply)                |                       |               | block6a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_project_conv      | (None, 7, 7, 192)     |       129,024 | block6a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6a_project_bn        | (None, 7, 7, 192)     |           768 | block6a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_expand_conv       | (None, 7, 7, 1152)    |       221,184 | block6a_project_bn[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_expand_bn         | (None, 7, 7, 1152)    |         4,608 | block6b_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_expand_activation | (None, 7, 7, 1152)    |             0 | block6b_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_dwconv            | (None, 7, 7, 1152)    |        28,800 | block6b_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_bn                | (None, 7, 7, 1152)    |         4,608 | block6b_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_activation        | (None, 7, 7, 1152)    |             0 | block6b_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_se_squeeze        | (None, 1152)          |             0 | block6b_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_se_reshape        | (None, 1, 1, 1152)    |             0 | block6b_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_se_reduce         | (None, 1, 1, 48)      |        55,344 | block6b_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_se_expand         | (None, 1, 1, 1152)    |        56,448 | block6b_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_se_excite         | (None, 7, 7, 1152)    |             0 | block6b_activation[0]… |
| (Multiply)                |                       |               | block6b_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_project_conv      | (None, 7, 7, 192)     |       221,184 | block6b_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_project_bn        | (None, 7, 7, 192)     |           768 | block6b_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_drop (Dropout)    | (None, 7, 7, 192)     |             0 | block6b_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block6b_add (Add)         | (None, 7, 7, 192)     |             0 | block6b_drop[0][0],    |
|                           |                       |               | block6a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_expand_conv       | (None, 7, 7, 1152)    |       221,184 | block6b_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_expand_bn         | (None, 7, 7, 1152)    |         4,608 | block6c_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_expand_activation | (None, 7, 7, 1152)    |             0 | block6c_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_dwconv            | (None, 7, 7, 1152)    |        28,800 | block6c_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_bn                | (None, 7, 7, 1152)    |         4,608 | block6c_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_activation        | (None, 7, 7, 1152)    |             0 | block6c_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_se_squeeze        | (None, 1152)          |             0 | block6c_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_se_reshape        | (None, 1, 1, 1152)    |             0 | block6c_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_se_reduce         | (None, 1, 1, 48)      |        55,344 | block6c_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_se_expand         | (None, 1, 1, 1152)    |        56,448 | block6c_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_se_excite         | (None, 7, 7, 1152)    |             0 | block6c_activation[0]… |
| (Multiply)                |                       |               | block6c_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_project_conv      | (None, 7, 7, 192)     |       221,184 | block6c_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_project_bn        | (None, 7, 7, 192)     |           768 | block6c_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_drop (Dropout)    | (None, 7, 7, 192)     |             0 | block6c_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block6c_add (Add)         | (None, 7, 7, 192)     |             0 | block6c_drop[0][0],    |
|                           |                       |               | block6b_add[0][0]      |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_expand_conv       | (None, 7, 7, 1152)    |       221,184 | block6c_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_expand_bn         | (None, 7, 7, 1152)    |         4,608 | block6d_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_expand_activation | (None, 7, 7, 1152)    |             0 | block6d_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_dwconv            | (None, 7, 7, 1152)    |        28,800 | block6d_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_bn                | (None, 7, 7, 1152)    |         4,608 | block6d_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_activation        | (None, 7, 7, 1152)    |             0 | block6d_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_se_squeeze        | (None, 1152)          |             0 | block6d_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_se_reshape        | (None, 1, 1, 1152)    |             0 | block6d_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_se_reduce         | (None, 1, 1, 48)      |        55,344 | block6d_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_se_expand         | (None, 1, 1, 1152)    |        56,448 | block6d_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_se_excite         | (None, 7, 7, 1152)    |             0 | block6d_activation[0]… |
| (Multiply)                |                       |               | block6d_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_project_conv      | (None, 7, 7, 192)     |       221,184 | block6d_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_project_bn        | (None, 7, 7, 192)     |           768 | block6d_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_drop (Dropout)    | (None, 7, 7, 192)     |             0 | block6d_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| block6d_add (Add)         | (None, 7, 7, 192)     |             0 | block6d_drop[0][0],    |
|                           |                       |               | block6c_add[0][0]      |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_expand_conv       | (None, 7, 7, 1152)    |       221,184 | block6d_add[0][0]      |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_expand_bn         | (None, 7, 7, 1152)    |         4,608 | block7a_expand_conv[0… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_expand_activation | (None, 7, 7, 1152)    |             0 | block7a_expand_bn[0][… |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_dwconv            | (None, 7, 7, 1152)    |        10,368 | block7a_expand_activa… |
| (DepthwiseConv2D)         |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_bn                | (None, 7, 7, 1152)    |         4,608 | block7a_dwconv[0][0]   |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_activation        | (None, 7, 7, 1152)    |             0 | block7a_bn[0][0]       |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_se_squeeze        | (None, 1152)          |             0 | block7a_activation[0]… |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_se_reshape        | (None, 1, 1, 1152)    |             0 | block7a_se_squeeze[0]… |
| (Reshape)                 |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_se_reduce         | (None, 1, 1, 48)      |        55,344 | block7a_se_reshape[0]… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_se_expand         | (None, 1, 1, 1152)    |        56,448 | block7a_se_reduce[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_se_excite         | (None, 7, 7, 1152)    |             0 | block7a_activation[0]… |
| (Multiply)                |                       |               | block7a_se_expand[0][… |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_project_conv      | (None, 7, 7, 320)     |       368,640 | block7a_se_excite[0][… |
| (Conv2D)                  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| block7a_project_bn        | (None, 7, 7, 320)     |         1,280 | block7a_project_conv[… |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| top_conv (Conv2D)         | (None, 7, 7, 1280)    |       409,600 | block7a_project_bn[0]… |
|---------------------------+-----------------------+---------------+------------------------|
| top_bn                    | (None, 7, 7, 1280)    |         5,120 | top_conv[0][0]         |
| (BatchNormalization)      |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| top_activation            | (None, 7, 7, 1280)    |             0 | top_bn[0][0]           |
| (Activation)              |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| avg_pool                  | (None, 1280)          |             0 | top_activation[0][0]   |
| (GlobalAveragePooling2D)  |                       |               |                        |
|---------------------------+-----------------------+---------------+------------------------|
| top_dropout (Dropout)     | (None, 1280)          |             0 | avg_pool[0][0]         |
|---------------------------+-----------------------+---------------+------------------------|
| predictions (Dense)       | (None, 1000)          |     1,281,000 | top_dropout[0][0]      |
+--------------------------------------------------------------------------------------------+
 Total params: 5,330,571 (20.33 MB)
 Trainable params: 5,288,548 (20.17 MB)
 Non-trainable params: 42,023 (164.16 KB)
Layer 0: input_layer
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 1: rescaling
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 2: normalization
  Input shape: None
  Output shape: None
  Number of parameters: 7
--------------------------------------------------
Layer 3: rescaling_1
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 4: stem_conv_pad
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 5: stem_conv
  Input shape: None
  Output shape: None
  Number of parameters: 864
--------------------------------------------------
Layer 6: stem_bn
  Input shape: None
  Output shape: None
  Number of parameters: 128
--------------------------------------------------
Layer 7: stem_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 8: block1a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 288
--------------------------------------------------
Layer 9: block1a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 128
--------------------------------------------------
Layer 10: block1a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 11: block1a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 12: block1a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 13: block1a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 264
--------------------------------------------------
Layer 14: block1a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 288
--------------------------------------------------
Layer 15: block1a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 16: block1a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 512
--------------------------------------------------
Layer 17: block1a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 64
--------------------------------------------------
Layer 18: block2a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 1536
--------------------------------------------------
Layer 19: block2a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 384
--------------------------------------------------
Layer 20: block2a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 21: block2a_dwconv_pad
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 22: block2a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 864
--------------------------------------------------
Layer 23: block2a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 384
--------------------------------------------------
Layer 24: block2a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 25: block2a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 26: block2a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 27: block2a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 388
--------------------------------------------------
Layer 28: block2a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 480
--------------------------------------------------
Layer 29: block2a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 30: block2a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 2304
--------------------------------------------------
Layer 31: block2a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 96
--------------------------------------------------
Layer 32: block2b_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 3456
--------------------------------------------------
Layer 33: block2b_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 576
--------------------------------------------------
Layer 34: block2b_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 35: block2b_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 1296
--------------------------------------------------
Layer 36: block2b_bn
  Input shape: None
  Output shape: None
  Number of parameters: 576
--------------------------------------------------
Layer 37: block2b_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 38: block2b_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 39: block2b_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 40: block2b_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 870
--------------------------------------------------
Layer 41: block2b_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 1008
--------------------------------------------------
Layer 42: block2b_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 43: block2b_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 3456
--------------------------------------------------
Layer 44: block2b_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 96
--------------------------------------------------
Layer 45: block2b_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 46: block2b_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 47: block3a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 3456
--------------------------------------------------
Layer 48: block3a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 576
--------------------------------------------------
Layer 49: block3a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 50: block3a_dwconv_pad
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 51: block3a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 3600
--------------------------------------------------
Layer 52: block3a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 576
--------------------------------------------------
Layer 53: block3a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 54: block3a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 55: block3a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 56: block3a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 870
--------------------------------------------------
Layer 57: block3a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 1008
--------------------------------------------------
Layer 58: block3a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 59: block3a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 5760
--------------------------------------------------
Layer 60: block3a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 160
--------------------------------------------------
Layer 61: block3b_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 9600
--------------------------------------------------
Layer 62: block3b_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 960
--------------------------------------------------
Layer 63: block3b_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 64: block3b_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 6000
--------------------------------------------------
Layer 65: block3b_bn
  Input shape: None
  Output shape: None
  Number of parameters: 960
--------------------------------------------------
Layer 66: block3b_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 67: block3b_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 68: block3b_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 69: block3b_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 2410
--------------------------------------------------
Layer 70: block3b_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 2640
--------------------------------------------------
Layer 71: block3b_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 72: block3b_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 9600
--------------------------------------------------
Layer 73: block3b_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 160
--------------------------------------------------
Layer 74: block3b_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 75: block3b_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 76: block4a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 9600
--------------------------------------------------
Layer 77: block4a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 960
--------------------------------------------------
Layer 78: block4a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 79: block4a_dwconv_pad
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 80: block4a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 2160
--------------------------------------------------
Layer 81: block4a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 960
--------------------------------------------------
Layer 82: block4a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 83: block4a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 84: block4a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 85: block4a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 2410
--------------------------------------------------
Layer 86: block4a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 2640
--------------------------------------------------
Layer 87: block4a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 88: block4a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 19200
--------------------------------------------------
Layer 89: block4a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 320
--------------------------------------------------
Layer 90: block4b_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 38400
--------------------------------------------------
Layer 91: block4b_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 92: block4b_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 93: block4b_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 4320
--------------------------------------------------
Layer 94: block4b_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 95: block4b_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 96: block4b_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 97: block4b_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 98: block4b_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 9620
--------------------------------------------------
Layer 99: block4b_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 10080
--------------------------------------------------
Layer 100: block4b_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 101: block4b_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 38400
--------------------------------------------------
Layer 102: block4b_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 320
--------------------------------------------------
Layer 103: block4b_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 104: block4b_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 105: block4c_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 38400
--------------------------------------------------
Layer 106: block4c_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 107: block4c_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 108: block4c_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 4320
--------------------------------------------------
Layer 109: block4c_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 110: block4c_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 111: block4c_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 112: block4c_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 113: block4c_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 9620
--------------------------------------------------
Layer 114: block4c_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 10080
--------------------------------------------------
Layer 115: block4c_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 116: block4c_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 38400
--------------------------------------------------
Layer 117: block4c_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 320
--------------------------------------------------
Layer 118: block4c_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 119: block4c_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 120: block5a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 38400
--------------------------------------------------
Layer 121: block5a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 122: block5a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 123: block5a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 12000
--------------------------------------------------
Layer 124: block5a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1920
--------------------------------------------------
Layer 125: block5a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 126: block5a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 127: block5a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 128: block5a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 9620
--------------------------------------------------
Layer 129: block5a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 10080
--------------------------------------------------
Layer 130: block5a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 131: block5a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 53760
--------------------------------------------------
Layer 132: block5a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 448
--------------------------------------------------
Layer 133: block5b_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 75264
--------------------------------------------------
Layer 134: block5b_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 135: block5b_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 136: block5b_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 16800
--------------------------------------------------
Layer 137: block5b_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 138: block5b_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 139: block5b_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 140: block5b_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 141: block5b_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 18844
--------------------------------------------------
Layer 142: block5b_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 19488
--------------------------------------------------
Layer 143: block5b_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 144: block5b_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 75264
--------------------------------------------------
Layer 145: block5b_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 448
--------------------------------------------------
Layer 146: block5b_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 147: block5b_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 148: block5c_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 75264
--------------------------------------------------
Layer 149: block5c_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 150: block5c_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 151: block5c_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 16800
--------------------------------------------------
Layer 152: block5c_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 153: block5c_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 154: block5c_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 155: block5c_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 156: block5c_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 18844
--------------------------------------------------
Layer 157: block5c_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 19488
--------------------------------------------------
Layer 158: block5c_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 159: block5c_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 75264
--------------------------------------------------
Layer 160: block5c_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 448
--------------------------------------------------
Layer 161: block5c_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 162: block5c_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 163: block6a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 75264
--------------------------------------------------
Layer 164: block6a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 165: block6a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 166: block6a_dwconv_pad
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 167: block6a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 16800
--------------------------------------------------
Layer 168: block6a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 2688
--------------------------------------------------
Layer 169: block6a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 170: block6a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 171: block6a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 172: block6a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 18844
--------------------------------------------------
Layer 173: block6a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 19488
--------------------------------------------------
Layer 174: block6a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 175: block6a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 129024
--------------------------------------------------
Layer 176: block6a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 768
--------------------------------------------------
Layer 177: block6b_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 178: block6b_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 179: block6b_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 180: block6b_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 28800
--------------------------------------------------
Layer 181: block6b_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 182: block6b_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 183: block6b_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 184: block6b_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 185: block6b_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 55344
--------------------------------------------------
Layer 186: block6b_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 56448
--------------------------------------------------
Layer 187: block6b_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 188: block6b_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 189: block6b_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 768
--------------------------------------------------
Layer 190: block6b_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 191: block6b_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 192: block6c_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 193: block6c_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 194: block6c_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 195: block6c_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 28800
--------------------------------------------------
Layer 196: block6c_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 197: block6c_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 198: block6c_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 199: block6c_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 200: block6c_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 55344
--------------------------------------------------
Layer 201: block6c_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 56448
--------------------------------------------------
Layer 202: block6c_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 203: block6c_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 204: block6c_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 768
--------------------------------------------------
Layer 205: block6c_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 206: block6c_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 207: block6d_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 208: block6d_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 209: block6d_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 210: block6d_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 28800
--------------------------------------------------
Layer 211: block6d_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 212: block6d_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 213: block6d_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 214: block6d_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 215: block6d_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 55344
--------------------------------------------------
Layer 216: block6d_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 56448
--------------------------------------------------
Layer 217: block6d_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 218: block6d_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 219: block6d_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 768
--------------------------------------------------
Layer 220: block6d_drop
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 221: block6d_add
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 222: block7a_expand_conv
  Input shape: None
  Output shape: None
  Number of parameters: 221184
--------------------------------------------------
Layer 223: block7a_expand_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 224: block7a_expand_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 225: block7a_dwconv
  Input shape: None
  Output shape: None
  Number of parameters: 10368
--------------------------------------------------
Layer 226: block7a_bn
  Input shape: None
  Output shape: None
  Number of parameters: 4608
--------------------------------------------------
Layer 227: block7a_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 228: block7a_se_squeeze
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 229: block7a_se_reshape
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 230: block7a_se_reduce
  Input shape: None
  Output shape: None
  Number of parameters: 55344
--------------------------------------------------
Layer 231: block7a_se_expand
  Input shape: None
  Output shape: None
  Number of parameters: 56448
--------------------------------------------------
Layer 232: block7a_se_excite
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 233: block7a_project_conv
  Input shape: None
  Output shape: None
  Number of parameters: 368640
--------------------------------------------------
Layer 234: block7a_project_bn
  Input shape: None
  Output shape: None
  Number of parameters: 1280
--------------------------------------------------
Layer 235: top_conv
  Input shape: None
  Output shape: None
  Number of parameters: 409600
--------------------------------------------------
Layer 236: top_bn
  Input shape: None
  Output shape: None
  Number of parameters: 5120
--------------------------------------------------
Layer 237: top_activation
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 238: avg_pool
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 239: top_dropout
  Input shape: None
  Output shape: None
  Number of parameters: 0
--------------------------------------------------
Layer 240: predictions
  Input shape: None
  Output shape: None
  Number of parameters: 1281000
--------------------------------------------------
